{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_functions as pf\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDict2D = {\n",
    "    \"1e3\": r\"D:\\Programming_Projects\\APRG\\ai_collaboration\\codes\\ThermalCavity\\Local_Plotting_Scripts\\models\\2023-12-10-22_05_35--Ra_1e3--nepochs_5e3\\Checkpoints\\5000_of_5000\",\n",
    "    \"1e4\": r\"D:\\Programming_Projects\\APRG\\ai_collaboration\\codes\\ThermalCavity\\Local_Plotting_Scripts\\models\\2023-12-10-22_05_44--Ra_1e4--nepochs_5e3\\Checkpoints\\5000_of_5000\",\n",
    "    \"1e5\": r\"D:\\Programming_Projects\\APRG\\ai_collaboration\\codes\\ThermalCavity\\Local_Plotting_Scripts\\models\\2023-12-10-22_05_51--Ra_1e5--nepochs_5e4\\Checkpoints\\50000_of_50000\",\n",
    "    \"1e6\": r\"D:\\Programming_Projects\\APRG\\ai_collaboration\\codes\\ThermalCavity\\Local_Plotting_Scripts\\models\\2023-12-10-22_05_55--Ra_1e6--nepochs_5e4\\Checkpoints\\50000_of_50000\"\n",
    "     }\n",
    "plotsWanted3D = {\n",
    "    \"1e3\": 1e3,\n",
    "    \"1e4\": 1e4,\n",
    "    \"1e5\": 1e5,\n",
    "    \"1e6\": 1e6\n",
    "}\n",
    "plot3D = r\"D:\\Programming_Projects\\APRG\\ai_collaboration\\codes\\ThermalCavity\\Local_Plotting_Scripts\\models\\2023-12-10-22_06_50--nepochs_3e4\\Checkpoints\\30000_of_30000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 150\n",
    "x = np.linspace(0,1,endpoint=True,num=nx)\n",
    "xx,yy = np.meshgrid(x,x)\n",
    "inputs = np.concatenate((xx.reshape(-1,1),yy.reshape(-1,1)),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "1e3 <class 'str'>\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "1e4 <class 'str'>\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "1e5 <class 'str'>\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "1e6 <class 'str'>\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    for ra in plotDict2D:\n",
    "        path = plotDict2D[ra]\n",
    "        model = keras.models.load_model(path)\n",
    "        outputs = pf.output_transform(model,inputs).numpy()\n",
    "        print(ra,type(ra))\n",
    "        pf.big_plot(outputs,xx,yy,nx,ra,save_path+\"2D_\")\n",
    "\n",
    "\n",
    "    model3D = keras.models.load_model(plot3D)\n",
    "    for plotWanted in plotsWanted3D:\n",
    "        ra = plotsWanted3D[plotWanted]\n",
    "        raInput = (np.log10(ra)-3)/3\n",
    "        xr,yr,zr = np.meshgrid(x,x,raInput)\n",
    "        inputsr = np.concatenate((xr.reshape(-1,1),yr.reshape(-1,1),zr.reshape(-1,1)),axis=1)\n",
    "        outputsr = pf.output_transform3d(model3D,inputsr).numpy()\n",
    "        pf.big_plot(outputsr,xr[:,:,0],yr[:,:,0],nx,plotWanted,save_path+\"3D_\")\n",
    "        pf.plotRaDerivatives(model3D,inputsr,nx,plotWanted,save_path+\"3D_\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thermalPlotting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
